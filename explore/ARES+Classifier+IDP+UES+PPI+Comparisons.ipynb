{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xc5iQhgvc1ms"
      },
      "source": [
        "# **ARES** Evaluation Strategies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OB2j0wpDL7dp"
      },
      "source": [
        "This notebook presents an in-depth exploration of the various configurations within **ARES**, highlighting comparative analyses and diverse evaluation strategies, including few-shot prompting and other frameworks such as RAGAS.\n",
        "\n",
        "**ARES** innovatively integrates synthetic data generation with fine-tuned classifiers to efficiently evaluate context relevance, answer faithfulness, and answer relevance, thereby reducing the reliance on extensive human annotations. By utilizing synthetic query generation and Prediction-Powered Inference (PPI), **ARES** ensures accurate evaluations with high statistical confidence."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84b_0sTgHZNG"
      },
      "source": [
        "### 1) Setting up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ymP8Ne5yLo06"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Optional for UES/IDP, configure API key for desired model(s)\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "remember to download datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7cDNq5wyTC57"
      },
      "outputs": [],
      "source": [
        "# Download Synthetic Query Dataset\n",
        "\n",
        "# https://drive.google.com/file/d/1e5jXjScVIXb1lRD7YQ0ENPGteMibNDTO/view?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "95nOtuqnPsH4"
      },
      "outputs": [],
      "source": [
        "# Download checkpoints for evaluation\n",
        "\n",
        "# Context Relevance: https://drive.google.com/file/d/1INyHfZpsUsn5UEBLSRehI9AX08AI12Lt/view?usp=sharing\n",
        "# Answer Relevance: https://drive.google.com/file/d/1yg1q6WrCwq7q07YceZUsd7FLVuLNJEue/view?usp=sharing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "explore dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Unlabeled evaluation set:\n",
            "Shape: (6189, 12)\n",
            "Columns: Index(['id', 'input', 'meta', 'output', 'wikipedia_id', 'Document',\n",
            "       'paragraph_number', 'Answer', 'Query', 'Context_Relevance_Label',\n",
            "       'Answer_Faithfulness_Label', 'Answer_Relevance_Label'],\n",
            "      dtype='object')\n",
            "\n",
            "First few rows:\n",
            "                    id                                              input  \\\n",
            "0 -6371603500131574271  who sings somebody's watching me with michael ...   \n",
            "1  6860341019198485637         who cracked the enigma code in world war 2   \n",
            "\n",
            "                                                meta  \\\n",
            "0  {'left_context': '', 'mention': '', 'right_con...   \n",
            "1  {'left_context': '', 'mention': '', 'right_con...   \n",
            "\n",
            "                                              output  wikipedia_id  \\\n",
            "0  [{'answer': 'Rockwell', 'meta': {'score': -1},...       1551152   \n",
            "1  [{'answer': 'Turing', 'meta': {'score': -1}, '...          1208   \n",
            "\n",
            "                                            Document  paragraph_number  \\\n",
            "0  \"Somebody's Watching Me\" is a song recorded by...               1.0   \n",
            "1                                      Alan Turing\\n               0.0   \n",
            "\n",
            "     Answer                                              Query  \\\n",
            "0  Rockwell  who sings somebody's watching me with michael ...   \n",
            "1    Turing         who cracked the enigma code in world war 2   \n",
            "\n",
            "   Context_Relevance_Label  Answer_Faithfulness_Label  Answer_Relevance_Label  \n",
            "0                      1.0                        1.0                     1.0  \n",
            "1                      1.0                        1.0                     1.0  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Read the few-shot prompts file\n",
        "prompts_df = pd.read_csv(\n",
        "    \"../data/ares/example_files/nq_few_shot_prompt_for_judge_scoring.tsv\", sep=\"\\t\"\n",
        ")\n",
        "\n",
        "# Read the unlabeled evaluation set\n",
        "eval_df = pd.read_csv(\"../data/ares/example_files/nq_labeled_output.tsv\", sep=\"\\t\")\n",
        "\n",
        "# # Basic exploration\n",
        "# print(\"\\nFew-shot prompts file:\")\n",
        "# print(\"Shape:\", prompts_df.shape)\n",
        "# print(\"Columns:\", prompts_df.columns)\n",
        "# print(\"\\nFirst few rows:\")\n",
        "# print(prompts_df.head())\n",
        "\n",
        "print(\"\\nUnlabeled evaluation set:\")\n",
        "print(\"Shape:\", eval_df.shape)\n",
        "print(\"Columns:\", eval_df.columns)\n",
        "print(\"\\nFirst few rows:\")\n",
        "print(eval_df.head(2))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ngNnQLsPc1mu"
      },
      "source": [
        "### 2) IDP + UES\n",
        "<p>Uses targeted prompts to enable pre-trained models to assess content relevance and accuracy in a zero-shot manner.</p>\n",
        "\n",
        "IDP is in-domain prompts\n",
        "UES is unlabeled evaluation sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "4xyOohqec1mu"
      },
      "outputs": [],
      "source": [
        "from ares import ARES\n",
        "\n",
        "ues_idp_config = {\n",
        "    # Dataset for in-domain prompts\n",
        "    \"in_domain_prompts_dataset\": \"../data/ares/example_files/nq_few_shot_prompt_for_judge_scoring.tsv\",\n",
        "    # Dataset for unlabeled evaluation\n",
        "    \"unlabeled_evaluation_set\": \"../data/ares/example_files/nq_output_5samples.tsv\",\n",
        "    # Model: GPT-3.5\n",
        "    \"model_choice\": \"gpt-4o\",\n",
        "}\n",
        "\n",
        "# Optional: Provide an alternative model of your choice below.\n",
        "# Here are some models you can choose from:\n",
        "# - mistralai/Mistral-7B-Instruct-v0.2\n",
        "# - mistralai/Mixtral-8x7B-Instruct-v0.1\n",
        "# - gpt-4-turbo-preview\n",
        "# - microsoft/deberta-v3-large\n",
        "# - openlm-research/open_llama_7b_v2\n",
        "# - mosaicml/mpt-7b-instruct"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "6FayDaXhc1mu"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3626340c78ca4c31a749bbd3a36d86cd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating large subset with gpt-4o:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of times did not extract Yes or No: 0\n",
            "{'Context Relevance Scores': 0.6, 'Answer Faithfulness Scores': 0.4, 'Answer Relevance Scores': 0.4, 'Raw Scores':    Context_Relevance_Score  Answer_Relevance_Score  Answer_Faithfulness_Score\n",
            "0                        1                       1                          1\n",
            "1                        1                       1                          1\n",
            "2                        0                       0                          0\n",
            "3                        1                       0                          0\n",
            "4                        0                       0                          0}\n"
          ]
        }
      ],
      "source": [
        "ares = ARES(ues_idp=ues_idp_config)\n",
        "results = ares.ues_idp()\n",
        "print(results)\n",
        "\n",
        "# {'Context Relevance Scores': [Score], 'Answer Faithfulness Scores': [Score], 'Answer Relevance Scores': [Score]}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_h9e-AQxc1mu"
      },
      "source": [
        "### 3) Training Classifier + IDP + UES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Cr4juU0Oc1mv"
      },
      "outputs": [],
      "source": [
        "from ares import ARES\n",
        "\n",
        "ues_idp_config = {\n",
        "    # Dataset for in-domain prompts\n",
        "    \"in_domain_prompts_dataset\": \"nq_few_shot_prompt_for_judge_scoring.tsv\",\n",
        "    # Dataset for unlabeled evaluation\n",
        "    \"unlabeled_evaluation_set\": \"nq_unlabeled_output.tsv\",\n",
        "    # Model: GPT-3.5\n",
        "    \"model_choice\": \"gpt-3.5-turbo-0125\",\n",
        "}\n",
        "\n",
        "# Training Classifier\n",
        "classifier_config = {\n",
        "    \"training_dataset\": [\"nq_synth_queries.tsv\"],\n",
        "    \"validation_set\": [\"nq_ratio_0.7.tsv\"],\n",
        "    \"label_column\": [\"Context_Relevance_Label\"],\n",
        "    \"num_epochs\": 10,\n",
        "    \"patience_value\": 3,\n",
        "    \"learning_rate\": 5e-6,\n",
        "    \"assigned_batch_size\": 1,\n",
        "    \"gradient_accumulation_multiplier\": 32,\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "m8tjD5iSc1mv"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/flowingpurplecrane/obs-all/obs/venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8d0d195c6df94b37bb1a3ad378ef619f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fa1037b750d94f4ebaa0d9f9fa422764",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/580 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9cbbb561a85445d7848f56b07b1f4aaf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------\n",
            "Starting new learning rate: 5e-06\n",
            "--------------------------------------------------------------------------\n",
            "Creating parent checkpoint directory: checkpoints/microsoft-deberta-v3-large\n",
            "--------------------------------------------------------------------------\n",
            "Dataset: nq_synth_queries.tsv\n",
            "Model: microsoft/deberta-v3-large\n",
            "Test Set Selection: nq_ratio_0.7.tsv\n",
            "Number of Runs: 1\n",
            "Learning Rate: 5e-06\n",
            "Checkpoint Path: checkpoints/microsoft-deberta-v3-large/Context_Relevance_Label_nq_ratio_0.7_2025-01-06_15:41:49.pt\n",
            "Patience: 3\n",
            "Validation Set Choice: True\n",
            "Number of Epochs: 10\n",
            "Number of warmup steps: 100\n",
            "--------------------------------------------------------------------------\n"
          ]
        },
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'nq_synth_queries.tsv'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m ares_module \u001b[38;5;241m=\u001b[39m ARES(classifier_model\u001b[38;5;241m=\u001b[39mclassifier_config)\n\u001b[0;32m----> 2\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mares_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_classifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(results)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Trains and saves checkpoints\u001b[39;00m\n",
            "File \u001b[0;32m~/obs-all/obs/venv/lib/python3.10/site-packages/ares/ares.py:137\u001b[0m, in \u001b[0;36mARES.train_classifier\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSkipping binary classifier configuration due to missing parameters.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 137\u001b[0m     \u001b[43mbinary_classifer_config\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclassifier_model_config\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/obs-all/obs/venv/lib/python3.10/site-packages/ares/binary_classifier.py:139\u001b[0m, in \u001b[0;36mbinary_classifer_config\u001b[0;34m(training_dataset, validation_set, label_column, num_epochs, patience_value, learning_rate, training_dataset_path, validation_dataset_path, model_choice, validation_set_scoring, assigned_batch_size, gradient_accumulation_multiplier, number_of_runs, num_warmup_steps, training_row_limit, validation_row_limit)\u001b[0m\n\u001b[1;32m    120\u001b[0m prepare_data_settings \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining_dataset_path\u001b[39m\u001b[38;5;124m\"\u001b[39m: training_dataset_path,\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlearning_rate_choices\u001b[39m\u001b[38;5;124m\"\u001b[39m: learning_rate_choices,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m: tokenizer\n\u001b[1;32m    135\u001b[0m }\n\u001b[1;32m    137\u001b[0m checkpoint_path, patience_value \u001b[38;5;241m=\u001b[39m prepare_and_clean_data(prepare_data_settings)\n\u001b[0;32m--> 139\u001b[0m synth_queries \u001b[38;5;241m=\u001b[39m \u001b[43manalyze_and_report_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_dataset_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_token_length\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m train_df, test_set \u001b[38;5;241m=\u001b[39m transform_data(synth_queries, validation_dataset_path, label)\n\u001b[1;32m    143\u001b[0m train_set_text, train_set_label, dev_set_text, dev_set_label, test_set_text, text_set_label_, labels_list \u001b[38;5;241m=\u001b[39m split_dataset(train_df, training_dataset_path, test_set, label)\n",
            "File \u001b[0;32m~/obs-all/obs/venv/lib/python3.10/site-packages/ares/LLM_as_a_Judge_Adaptation/General_Binary_Classifier.py:391\u001b[0m, in \u001b[0;36manalyze_and_report_data\u001b[0;34m(dataset, label_column, tokenizer, max_token_length)\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;124;03mAnalyzes and reports data from a given dataset.\u001b[39;00m\n\u001b[1;32m    380\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;124;03m- pd.DataFrame: A DataFrame containing the processed and filtered data.\u001b[39;00m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    390\u001b[0m \u001b[38;5;66;03m# Read the dataset\u001b[39;00m\n\u001b[0;32m--> 391\u001b[0m synth_queries \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\t\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    393\u001b[0m \u001b[38;5;66;03m# If the dataset is reformatted, rename columns accordingly\u001b[39;00m\n\u001b[1;32m    394\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnq_reformatted\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m dataset:\n",
            "File \u001b[0;32m~/obs-all/obs/venv/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/obs-all/obs/venv/lib/python3.10/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
            "File \u001b[0;32m~/obs-all/obs/venv/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/obs-all/obs/venv/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
            "File \u001b[0;32m~/obs-all/obs/venv/lib/python3.10/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'nq_synth_queries.tsv'"
          ]
        }
      ],
      "source": [
        "ares_module = ARES(classifier_model=classifier_config)\n",
        "results = ares_module.train_classifier()\n",
        "print(results)\n",
        "\n",
        "# Trains and saves checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UKJ6wsu_c1mv"
      },
      "outputs": [],
      "source": [
        "ares = ARES(ues_idp=ues_idp_config)\n",
        "results = ares.ues_idp()\n",
        "print(results)\n",
        "\n",
        "# {'Context Relevance Scores': [Score], 'Answer Faithfulness Scores': [Score], 'Answer Relevance Scores': [Score]}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_U7FplrWc1mv"
      },
      "source": [
        "## 4) Training Classifier + PPI + UES"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONLlOK5Kc1mv"
      },
      "source": [
        "<h3>UES</h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xaczTIcrc1mv"
      },
      "outputs": [],
      "source": [
        "from ares import ARES\n",
        "\n",
        "ues_idp_config = {\n",
        "    # Dataset for in-domain prompts\n",
        "    \"in_domain_prompts_dataset\": \"nq_few_shot_prompt_for_judge_scoring.tsv\",\n",
        "    # Dataset for unlabeled evaluation\n",
        "    \"unlabeled_evaluation_set\": \"nq_unlabeled_output.tsv\",\n",
        "    # Default model choice\n",
        "    \"model_choice\": \"gpt-3.5-turbo-1106\",\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mjpM9CAhc1mv"
      },
      "outputs": [],
      "source": [
        "ares = ARES(ues_idp=ues_idp_config)\n",
        "results = ares.ues_idp()\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbyCUvHYc1mw"
      },
      "source": [
        "<h3>Training Classifier</h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1HFZOEG7c1mw"
      },
      "source": [
        "<p>Generates checkpoint which is used in PPI below</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aGJnHe51c1mw"
      },
      "outputs": [],
      "source": [
        "from ares import ARES\n",
        "\n",
        "classifier_config = {\n",
        "    \"training_dataset\": [\"nq_synth_queries.tsv\"],\n",
        "    \"validation_set\": [\"nq_ratio_0.7.tsv\"],\n",
        "    \"label_column\": [\"Context_Relevance_Label\"],\n",
        "    \"num_epochs\": 10,\n",
        "    \"patience_value\": 3,\n",
        "    \"learning_rate\": 5e-6,\n",
        "    \"assigned_batch_size\": 1,\n",
        "    \"gradient_accumulation_multiplier\": 32,\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dX5JRi2kc1mw"
      },
      "outputs": [],
      "source": [
        "ares = ARES(classifier_model=classifier_config)\n",
        "results = ares.train_classifier()\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rn9-2CZFc1mw"
      },
      "source": [
        "<h3>PPI</h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fWA3pJ7yc1mw"
      },
      "outputs": [],
      "source": [
        "from ares import ARES\n",
        "\n",
        "ppi_config = {\n",
        "    \"evaluation_datasets\": [\"nq_unlabeled_output.tsv\"],\n",
        "    \"checkpoints\": [\"Context_Relevance_Label_joint_trained_date_time.pt\"],\n",
        "    \"labels\": [\"Context_Relevance_Label\"],\n",
        "    \"rag_type\": \"question_answering\",\n",
        "    \"gold_label_paths\": [\"nq_labeled_output.tsv\"],\n",
        "    \"prediction_filepaths\": [\"nq_0.6_predictions_updated.tsv\"],\n",
        "}\n",
        "\n",
        "# Install checkpoint here!\n",
        "# Context Relevance: https://drive.google.com/file/d/1INyHfZpsUsn5UEBLSRehI9AX08AI12Lt/view?usp=sharing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FNVTrg7Fc1mw"
      },
      "outputs": [],
      "source": [
        "ares = ARES(ppi=ppi_config)\n",
        "results = ares.evaluate_RAG()\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGEHOev9c1mw"
      },
      "source": [
        "## 5) ARES Comparison to RAGAS and Zeroshot Llama and Mixtral"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4m-vFqyhc1mw"
      },
      "source": [
        "<h3>ARES Configuration</h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xyWiTf0Ec1mw"
      },
      "source": [
        "<p>Synthetic Generator</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZKwLLAcCc1mw"
      },
      "outputs": [],
      "source": [
        "from ares import ARES\n",
        "\n",
        "synth_config = {\n",
        "    \"document_filepaths\": [\"/content/nq_unlabeled_output.tsv\"],\n",
        "    \"few_shot_prompt_filenames\": [\"/content/nq_few_shot_prompt_for_judge_scoring.tsv\"],\n",
        "    \"synthetic_queries_filenames\": [\"nq_synthetic_queries.tsv\"],\n",
        "    \"documents_sampled\": 6189,\n",
        "}\n",
        "\n",
        "ares_module = ARES(synthetic_query_generator=synth_config)\n",
        "results = ares_module.generate_synthetic_data()\n",
        "print(results)\n",
        "\n",
        "# Generates and saves synthetic queries\n",
        "\n",
        "# Install Synthetic Query File here!\n",
        "# https://drive.google.com/file/d/1e5jXjScVIXb1lRD7YQ0ENPGteMibNDTO/view?usp=sharing\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4pJSMYQc1mx"
      },
      "source": [
        "<p>Training Classifier</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w4sSC3RSc1mx"
      },
      "outputs": [],
      "source": [
        "from ares import ARES\n",
        "\n",
        "classifier_config = {\n",
        "    \"training_dataset\": [\"nq_synth_queries.tsv\"],\n",
        "    \"validation_set\": [\"nq_ratio_0.7.tsv\"],\n",
        "    \"label_column\": [\"Context_Relevance_Label\", \"Answer_Relevance_Label\"],\n",
        "    \"num_epochs\": 10,\n",
        "    \"patience_value\": 3,\n",
        "    \"learning_rate\": 5e-6,\n",
        "    \"assigned_batch_size\": 1,\n",
        "    \"gradient_accumulation_multiplier\": 32,\n",
        "}\n",
        "\n",
        "ares = ARES(classifier_model=classifier_config)\n",
        "results = ares.train_classifier()\n",
        "print(results)\n",
        "\n",
        "# Trains and saves classifier for context relevance and answer relevance\n",
        "\n",
        "# Download checkpoints here!\n",
        "\n",
        "# Context Relevance: https://drive.google.com/file/d/1INyHfZpsUsn5UEBLSRehI9AX08AI12Lt/view?usp=sharing\n",
        "# Answer Relevance: https://drive.google.com/file/d/1yg1q6WrCwq7q07YceZUsd7FLVuLNJEue/view?usp=sharing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "poWdw0kfc1mx"
      },
      "source": [
        "<p>PPI</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LkYn3dONc1mx",
        "outputId": "2413b041-85a1-4b5a-8069-b73bd8ee7bd8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Context_Relevance_Label Scoring\n",
            "ARES Ranking\n",
            "ARES Prediction: [0.6056978059262574]\n",
            "ARES Confidence Interval: [[0.547, 0.664]]\n",
            "Number of Examples in Evaluation Set: [4421]\n",
            "Ground Truth Performance: [0.6]\n",
            "ARES LLM Judge Accuracy on Ground Truth Labels: [0.789]\n",
            "Annotated Examples used for PPI: 300\n",
            "------------\n",
            "\n",
            "Answer_Relevance_Label Scoring\n",
            "ARES Ranking\n",
            "ARES Prediction: [0.5955191133227766]\n",
            "ARES Confidence Interval: [[0.577, 0.614]]\n",
            "Number of Examples in Evaluation Set: [4421]\n",
            "Ground Truth Performance: [0.6]\n",
            "ARES LLM Judge Accuracy on Ground Truth Labels: [0.977]\n",
            "Annotated Examples used for PPI: 300\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from ares import ARES\n",
        "\n",
        "ppi_config = {\n",
        "    \"evaluation_datasets\": [\"nq_unlabeled_output.tsv\"],\n",
        "    \"checkpoints\": [\n",
        "        \"Context_Relevance_Label_joint_trained_date_time.pt\",\n",
        "        \"Answer_Relevance_Label_joint_trained_date_time.pt\",\n",
        "    ],\n",
        "    \"rag_type\": \"question_answering\",\n",
        "    \"labels\": [\"Context_Relevance_Label\", \"Answer_Relevance_Label\"],\n",
        "    \"gold_label_path\": \"nq_labeled_output.tsv\",\n",
        "}\n",
        "\n",
        "ares_module = ARES(ppi=ppi_config)\n",
        "results = ares_module.evaluate_RAG()\n",
        "print(results)\n",
        "\n",
        "# Evaluation numbers below should match"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0-LcdeQc1mx"
      },
      "source": [
        "<h3>RAGAS Configuration</h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UvvqMNDkc1mx"
      },
      "source": [
        "<p>Data Cleaning | Context Relevance Label Filter</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "H_UrINgrc1my"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset, Dataset\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "\n",
        "def load_and_prepare_dataset(file_path):\n",
        "    # Load the dataset from the TSV file\n",
        "    dataset_df = pd.read_csv(file_path, delimiter=\"\\t\")\n",
        "\n",
        "    # Remove rows where 'Context_Relevance_Label' has no values\n",
        "    dataset_df = dataset_df.dropna(subset=[\"Context_Relevance_Label\"])\n",
        "\n",
        "    # Convert 'Context_Relevance_Label' to string if it is not already\n",
        "    dataset_df[\"Context_Relevance_Label\"] = dataset_df[\n",
        "        \"Context_Relevance_Label\"\n",
        "    ].astype(str)\n",
        "\n",
        "    # Use 'Context_Relevance_Label' as 'ground_truth'\n",
        "    prepared_data = {\n",
        "        \"question\": dataset_df[\"Query\"].tolist(),\n",
        "        \"contexts\": [\n",
        "            [doc] for doc in dataset_df[\"Document\"].tolist()\n",
        "        ],  # Contexts are expected to be list of lists\n",
        "        \"answer\": dataset_df[\"Answer\"].tolist(),\n",
        "        \"ground_truth\": dataset_df[\n",
        "            \"Context_Relevance_Label\"\n",
        "        ].tolist(),  # Using 'Context_Relevance_Label' as 'ground_truth'\n",
        "    }\n",
        "\n",
        "    # Convert to HuggingFace's Dataset format\n",
        "    dataset = Dataset.from_dict(prepared_data)\n",
        "    return dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rO6_1XBQc1my"
      },
      "source": [
        "<p> ARES Label Filter: Removes rows w/ no values for specified label</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NxtzFOmdc1my"
      },
      "source": [
        "<p>Context Relevance Accuracy</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "inWA-43Qc1my",
        "outputId": "d58db3f5-aacc-43da-86dc-c0adeaf1c62e"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2221d4bc28e84cf19f55567fdbcb7a82",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/22 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'context_precision': 0.3636, 'context_recall': 0.0000}\n"
          ]
        }
      ],
      "source": [
        "from ragas import evaluate\n",
        "from ragas.metrics import context_recall, context_precision\n",
        "\n",
        "# Load and prepare the dataset\n",
        "file_path = \"../data/ares/example_files/nq_output_15samples.tsv\"  # Update with the actual file path\n",
        "prepared_dataset = load_and_prepare_dataset(file_path)\n",
        "\n",
        "# Specify metrics\n",
        "metrics = [\n",
        "    context_precision,\n",
        "    context_recall,\n",
        "]\n",
        "\n",
        "result = evaluate(prepared_dataset, metrics=metrics)  # Pass the initialized llm\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yy3J9wDpc1my"
      },
      "source": [
        "<p>Data Cleaning | Answer Relevance Label Filter</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "6ohU4REhc1my"
      },
      "outputs": [],
      "source": [
        "from datasets import Dataset\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "def load_and_prepare_dataset(file_path):\n",
        "    # Load the dataset from the TSV file\n",
        "    dataset_df = pd.read_csv(file_path, delimiter=\"\\t\")\n",
        "\n",
        "    dataset_df = dataset_df.dropna(subset=[\"Answer_Relevance_Label\"])\n",
        "\n",
        "    # Convert 'Context_Relevance_Label' to string if it is not already\n",
        "    dataset_df[\"Answer_Relevance_Label\"] = dataset_df[\"Answer_Relevance_Label\"].astype(\n",
        "        str\n",
        "    )\n",
        "\n",
        "    # Use 'Context_Relevance_Label' as 'ground_truth'\n",
        "    prepared_data = {\n",
        "        \"user_input\": dataset_df[\"Query\"].tolist(),\n",
        "        \"retrieved_contexts\": [[doc] for doc in dataset_df[\"Document\"].tolist()],\n",
        "        \"response\": dataset_df[\"Answer\"].tolist(),\n",
        "        \"ground_truth\": dataset_df[\"Answer_Relevance_Label\"].tolist(),\n",
        "    }\n",
        "\n",
        "    # Convert to HuggingFace's Dataset format\n",
        "    dataset = Dataset.from_dict(prepared_data)\n",
        "    return dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "note that single word responses causes problems with RAGAS, not designed for this purpose\n",
        "\n",
        "RAGAS doesn't work with single word answers!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "IC2CUOatc1my",
        "outputId": "b23bd11d-63c4-4ebf-a025-2ff80fb39a06"
      },
      "outputs": [],
      "source": [
        "from ragas import evaluate\n",
        "from ragas.metrics import answer_relevancy, faithfulness\n",
        "\n",
        "file_path = \"../data/ares/example_files/nq_output_15samples.tsv\"\n",
        "prepared_dataset = load_and_prepare_dataset(file_path)\n",
        "\n",
        "# Specify metrics\n",
        "metrics = [answer_relevancy, faithfulness]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "84c7fafe84b6495b8185ad2699e54a92",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/22 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Rockwell']\n",
            "{0: 'Rockwell'}\n",
            "['Turing']\n",
            "{0: 'Turing'}\n",
            "['Pittsburgh']\n",
            "{0: 'Pittsburgh'}\n",
            "['2010']\n",
            "{0: '2010'}\n",
            "['Erica Rivera']\n",
            "{0: 'Erica Rivera'}\n",
            "['Bob Dylan']\n",
            "{0: 'Bob Dylan'}\n",
            "['1983']\n",
            "{0: '1983'}\n",
            "['On June 27 , 1954']\n",
            "{}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No statements were generated from the answer.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['5 %']\n",
            "{0: '5 %'}\n",
            "['22 July 1947']\n",
            "{}\n",
            "['in the 1980s']\n",
            "{}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No statements were generated from the answer.\n",
            "No statements were generated from the answer.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'answer_relevancy': 0.6982, 'faithfulness': 0.1250}\n"
          ]
        }
      ],
      "source": [
        "# Evaluate\n",
        "result = evaluate(prepared_dataset, metrics=metrics)\n",
        "\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_input</th>\n",
              "      <th>retrieved_contexts</th>\n",
              "      <th>response</th>\n",
              "      <th>reference</th>\n",
              "      <th>answer_relevancy</th>\n",
              "      <th>faithfulness</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>who sings somebody's watching me with michael ...</td>\n",
              "      <td>[\"Somebody's Watching Me\" is a song recorded b...</td>\n",
              "      <td>Rockwell</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.579954</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>who cracked the enigma code in world war 2</td>\n",
              "      <td>[Alan Turing\\n]</td>\n",
              "      <td>Turing</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.746280</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>where do characters live in this is us</td>\n",
              "      <td>[Most episodes feature a storyline taking plac...</td>\n",
              "      <td>Pittsburgh</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.648006</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>when did slave to the rhythm come out</td>\n",
              "      <td>[The song was written and recorded in 1990, wi...</td>\n",
              "      <td>2010</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.726683</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>who plays bianca in that's so raven</td>\n",
              "      <td>[BULLET::::- Bianca, played by Erica Rivera\\n]</td>\n",
              "      <td>Erica Rivera</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.615961</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>who is playing halftime show super bowl 50</td>\n",
              "      <td>[The Super Bowl 50 Halftime Show took place on...</td>\n",
              "      <td>Bob Dylan</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.685556</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>how did early humans make use of stones during...</td>\n",
              "      <td>[Prehistoric technology is technology that pre...</td>\n",
              "      <td>1983</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.728894</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>philadelphia is known as the city of what</td>\n",
              "      <td>[Penn named the city Philadelphia, which is Gr...</td>\n",
              "      <td>On June 27 , 1954</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.719964</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>the probability of making a type i error when ...</td>\n",
              "      <td>[If the probability of obtaining a result as e...</td>\n",
              "      <td>5 %</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.762169</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>when was the national flag of india adopted</td>\n",
              "      <td>[The National Flag of India is a horizontal re...</td>\n",
              "      <td>22 July 1947</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.735336</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>when was the land rover defender first built</td>\n",
              "      <td>[The Land Rover Defender (initially called the...</td>\n",
              "      <td>in the 1980s</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.731569</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           user_input  \\\n",
              "0   who sings somebody's watching me with michael ...   \n",
              "1          who cracked the enigma code in world war 2   \n",
              "2              where do characters live in this is us   \n",
              "3               when did slave to the rhythm come out   \n",
              "4                 who plays bianca in that's so raven   \n",
              "5          who is playing halftime show super bowl 50   \n",
              "6   how did early humans make use of stones during...   \n",
              "7           philadelphia is known as the city of what   \n",
              "8   the probability of making a type i error when ...   \n",
              "9         when was the national flag of india adopted   \n",
              "10       when was the land rover defender first built   \n",
              "\n",
              "                                   retrieved_contexts           response  \\\n",
              "0   [\"Somebody's Watching Me\" is a song recorded b...           Rockwell   \n",
              "1                                     [Alan Turing\\n]             Turing   \n",
              "2   [Most episodes feature a storyline taking plac...         Pittsburgh   \n",
              "3   [The song was written and recorded in 1990, wi...               2010   \n",
              "4      [BULLET::::- Bianca, played by Erica Rivera\\n]       Erica Rivera   \n",
              "5   [The Super Bowl 50 Halftime Show took place on...          Bob Dylan   \n",
              "6   [Prehistoric technology is technology that pre...               1983   \n",
              "7   [Penn named the city Philadelphia, which is Gr...  On June 27 , 1954   \n",
              "8   [If the probability of obtaining a result as e...                5 %   \n",
              "9   [The National Flag of India is a horizontal re...       22 July 1947   \n",
              "10  [The Land Rover Defender (initially called the...       in the 1980s   \n",
              "\n",
              "   reference  answer_relevancy  faithfulness  \n",
              "0        1.0          0.579954           1.0  \n",
              "1        1.0          0.746280           0.0  \n",
              "2        1.0          0.648006           0.0  \n",
              "3        1.0          0.726683           0.0  \n",
              "4        1.0          0.615961           0.0  \n",
              "5        0.0          0.685556           0.0  \n",
              "6        0.0          0.728894           0.0  \n",
              "7        0.0          0.719964           NaN  \n",
              "8        1.0          0.762169           0.0  \n",
              "9        1.0          0.735336           NaN  \n",
              "10       1.0          0.731569           NaN  "
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results_df = result.to_pandas()\n",
        "results_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6OXxQ9TXc1my"
      },
      "source": [
        "<h3>Zeroshot Llama Configuration</h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wBDuO0n5c1mz"
      },
      "outputs": [],
      "source": [
        "from ares import ARES\n",
        "\n",
        "\n",
        "ues_idp_config = {\n",
        "    # Dataset for in-domain prompts\n",
        "    \"in_domain_prompts_dataset\": \"nq_few_shot_prompt_for_judge_scoring.tsv\",\n",
        "    # Dataset for unlabeled evaluation\n",
        "    \"unlabeled_evaluation_set\": \"nq_unlabeled_output.tsv\",\n",
        "    # Model: Mistral 7B\n",
        "    \"model_choice\": \"codellama/CodeLlama-13b-Instruct-hf\",\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KfWNktotc1mz"
      },
      "outputs": [],
      "source": [
        "ares = ARES(ues_idp=ues_idp_config)\n",
        "results = ares.ues_idp()\n",
        "print(results)\n",
        "\n",
        "# {'Context Relevance Scores': [Score], 'Answer Faithfulness Scores': [Score], 'Answer Relevance Scores': [Score]}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWYccnFdc1mz"
      },
      "source": [
        "<h3>Zeroshot Mistral Configuration</h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "529wPxsCc1mz"
      },
      "outputs": [],
      "source": [
        "from ares import ARES\n",
        "import os\n",
        "\n",
        "ues_idp_config = {\n",
        "    # Dataset for in-domain prompts\n",
        "    \"in_domain_prompts_dataset\": \"nq_few_shot_prompt_for_judge_scoring.tsv\",\n",
        "    # Dataset for unlabeled evaluation\n",
        "    \"unlabeled_evaluation_set\": \"nq_unlabeled_output.tsv\",\n",
        "    # Model: Mistral 7B\n",
        "    \"model_choice\": \"mistralai/Mixtral-8x7B-v0.1\",\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8QA8sWllc1mz"
      },
      "outputs": [],
      "source": [
        "ares = ARES(ues_idp=ues_idp_config)\n",
        "results = ares.ues_idp()\n",
        "print(results)\n",
        "\n",
        "# {'Context Relevance Scores': [Score], 'Answer Faithfulness Scores': [Score], 'Answer Relevance Scores': [Score]}"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
